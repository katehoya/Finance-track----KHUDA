# 14. CNN  
![image](https://github.com/user-attachments/assets/781b8370-5c12-44b1-86c7-68fb10b0ca8d)
 - 첫 번째 층에선 작은 저수준 특성에 집중하고, 그다음 은닉 층에선 더 큰 고수준 특성을 분석한다.
 - 패딩 : 컨볼루션 연산에서 출력 크기를 조정하고, 가장자리 픽셀들도 연산에 잘 반영되도록 하는 기법.  
![image](https://github.com/user-attachments/assets/b0595c93-af55-40a3-a7e0-2d4da776ab0b)  

 - CNN은 완전연결층인 MLP와 달리, 희소연결이기 때문에 입력층의 크기와 무관하게 이전 층의 노드 중 일정한 개수의 노드들과만 상호작용(가중치 연결)한다.
   -> 그래서 가변 크기의 입력에 대응하기 좋다.
   
 
 - CNN은 격자 구조를 가진 데이터에 적합하다!! ex) 영상 or 음성.
 - CNN 쓰기 안 좋은 예 : Iris x = (꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비)T

## 14.2.1 필터  
필터의 역할 : ![image](https://github.com/user-attachments/assets/7f640855-68b8-4844-bffa-6e94c8224302)  
수직 필터 : 가운데 수직으로 1이 있고 나머지는 0. 수평 필터 : 가운데 수평으로 1이 있고 나머지는 0.  
 - 필터는 수동으로 만드는 게 아니라, 훈련하는 동안 합성곱 층이 자동으로 최적의 필터를 찾음.

![image](https://github.com/user-attachments/assets/8cc83a13-8031-435a-8e69-b92867807974)  
1 convolutional layer가 input에 여러 필터를 동시에 적용하여 input에 있는 여러 특성을 감지할 수도 있다.  
Feature Map : 1개의 filter가 생성하는 출력.  
![image](https://github.com/user-attachments/assets/12515a78-a2ba-44b2-8a78-361d528ce2ba)  

## 14.3 Pooling layer  
풀링 층의 목적 : 계산량과 메모리, (오버피팅을 방지하는) 파라미터 수를 줄이기 위해 입력 이미지의 축소판을 만드는 것.  
플링은 가중치가 없고, 기존 값들 중에서 최대 or 평균 값등을 대표로 사용함.  
![image](https://github.com/user-attachments/assets/2e33c534-70cf-4705-ac38-c76947b3a66d)  
 - 또한 회전과 확대, 축소와 같은 작은 변화에 대한 약간의 불변성도 제공한다.
   -> 물체 인식이나 영상 검색 등의 문제에 매우 효율적.
![image](https://github.com/user-attachments/assets/d3d5dacb-3956-4e25-a307-b5912db5b79e)  
 - 그러나 입력값의 다수를 잃게 될 뿐만 아니라 불변성이 크게 필요하지 않는 분야에선 좋지 않다.

## 14.5 CNN  
![image](https://github.com/user-attachments/assets/d272b994-9652-44c6-a95c-bba73176c75c)  
네트워크를 통과할수록 이미지는 점점 작아지지만 합성곱 층 때문에 더 깊어짐. 더 많은 특성 맵.  

### 14.5.1 LeNet  
![image](https://github.com/user-attachments/assets/7f518691-373b-4a12-b77b-605cc73fd9ac)  
### 14.5.2 AlexNet  
![image](https://github.com/user-attachments/assets/e72a5cdd-30af-48db-9677-317b0dccf87d)  
 - LeNet보다 컨볼루션 층 2개 추가, 완전연결 층 1개 추가.
 - 활성함수로 ReLU 사용, 지역 반응 정규화 기법 사용
 - 드롭아웃, 데이터 확대 규제 기법 사용
 - PCA르 ㄹ이용하여 영상 컬러값을 변환해 영상의 개수를 추가로 늘림.
### 14.5.3 GoogLeNet  
 - 인셉션 모듈
![image](https://github.com/user-attachments/assets/bb4e2c5e-c0f7-46c8-8b24-a3025583375b)  
 - 1 x 1 커널의 합성곱 층의 이유 : 공간상의 패턴을 잡을 수는 없지만 깊이 차원(채널)을 따라 놓인 패턴을 잡을 수 있다.
 - 입력보다 더 작은 특성 맵을 활용하므로 차원을 줄인다는 의미의 병목 층의 역할을 한다.
![image](https://github.com/user-attachments/assets/6c599aae-658f-47e2-9435-3ab9ef95aa63)
### 14.5.5 ResNet  

### 14.5.6 Xception  

### 14.5.7 SENet  


## 14.9 분류와 위치 추정  
물체의 위치 추정 : 물체 주위의 바운딩 박스 추정.  
![image](https://github.com/user-attachments/assets/6551df57-f99e-402e-ab91-911fd2dc8657)  
IOU : insertion of union. 교집합 / 합집합.  

## 14.10 객체 탐지  
객체 탐지 : 하나의 이미지에서 여러 물체를 분류하고 위치를 추정하는 것.  

### 14.10.1 완전 합성곱 신경망  

### 14.10.2 YOLO  

## 14.11 객체 추적  

## 14.12 시맨틱 분할  

***

# 15. RNN  
## 15.1 순환 뉴런과 순환 층  
새 입력과, 이전 뉴런에서의 출력을 입력으로 받는다.  
첫 번째 time step에선 보통 0이라고 가정.  
![image](https://github.com/user-attachments/assets/31c5dd9f-2ca2-4c6e-b19b-730c9cb6e8dc)  
![image](https://github.com/user-attachments/assets/ca7322b2-ec48-49e9-90d4-9051f4c8c2a3)  
가중치도 입력 X에 대한 가중치, 이전 뉴런의 출력 Y에 대한 가중치 이렇게 2개를 가진다.  
![image](https://github.com/user-attachments/assets/820af70b-f2e5-422c-aeb1-253dd676429f)  
![image](https://github.com/user-attachments/assets/fb481bac-11ca-43b0-aab1-1c6dec5fee2b)  
정확히는 셀의 출력이 아니라 셀의 (히든)상태를 입력으로 받는 것이다.  
그러나 셀의 상태와 출력은 다를 수도 있다.  
셀의 상태와 출력 모두 X, Y에 대한 함수이다.  
![image](https://github.com/user-attachments/assets/a1520876-408e-4d38-a17f-2fc835070a98)  

![image](https://github.com/user-attachments/assets/f1cfc447-9ff6-4cc9-8a6a-9102ecf5d25d)  
ex)  
시퀀스 투 시퀀스 : 가정의 일일 전력 사용량 예측  
시퀀스 투 벡터 : 영화 리뷰에 있는 연속된 단어를 주입하면 관람객의 감성 점수 출력  
벡터 투 시퀀스 : 이미지를 넣으면 그와 관련된 캡션을 출력  
인코더 - 디코더 : 한 언어의 문장을 주입하면 다른 언어로 번역해주는 기능  

## 15.2 RNN 훈련하기  
BPTT (Backpropagation Through Time)  
![image](https://github.com/user-attachments/assets/f68cb97e-5315-4f4a-b704-6dd9d180357e)  
 - Y는 타깃, Y^은 예측(출력).  
 - 손실 함수는 시퀀스 투 벡터처럼 일부 출력을 무시할 수 있다.(Y0, Y1)
 - 나온 출력을 가지고 다시 파라미터 조정.
 - 일반적인 역전파와 크게 다르지 않다.

## 15.3 시계열 예측  
 - 시계열  
 - 단변량 시계열 : 1 time step에 값이 1개  
 - 다변량 시계열 : 1 time step에 값이 여러 개  
 - 계절성 : 비슷한 패턴이 반복되는 것.  
 - 단순 예측 : 일주일(꼭 일주일이 아니더라도 패턴의 이전 주기) 전 값을 미래의 예측값으로 사용하는 것.  
 - 차분 : 원래 시계열과, 다른 시계열(t 대신 t-7 쓴 시계열)간 차이  
 - 자기상관 : 시계열이 시간이 지연된 자기자신과 상관관계를 가지는 것.
 - MAE : Mean Absolute Error
 - MAPE : Mean Absolute Percentage Error
![image](https://github.com/user-attachments/assets/aeb19062-cdf2-4a69-b206-9c11482ddec2)
 - 차분 : 계절성과 트렌드를 없앤다.
 - 이 그림에서도 16 ~ 19년 사이의 감소 트렌드가 차분 그래프에선 그냥 거의 일정한 음수값으로 나온다.
![image](https://github.com/user-attachments/assets/38ddafcc-41f4-44b3-a869-1c9d52f5836c)

### 15.3.1 ARMA 모델  
자기 회귀 이동 평균(Auto Regressive Moving Average) :   
![image](https://github.com/user-attachments/assets/d432ff54-6fdf-49bc-b97c-487f188b36be)  
앞 항(AR) : 시계열의 지난 time step의 가중치 합. hyperparameter p로 모델이 얼마나 먼 과거를 바라볼 지 결정함.(자기상관)  
두 번째 항(MA) : 지난 예측 오차의 가중치 합. 모델의 이동 평균.  

ARMA 모델의 한계 : 정상 시계열(평균, 분산이 일정한)을 가정한다는 점이다.  

 - 1 time step에 대한 차분을 구하면 시계열의 도함수를 근사할 수 있다!
 - 선형적인 트렌드를 제거 가능. ex) [3,5,7,9,11]  ->  [2,2,2,2]
 - if 선형적인 트렌드가 아니라, 2차 방정식 형태의 트렌드를 가진다면 한 번의 제거로는 불충분.
 - ex) [1,4,9,16,25,36]  ->  [3,5,7,9,11]  ->  [2,2,2,2]
 -> 일반적으로 d번의 차분을 적용하면 d차 도함수를 근사할 수 있다. (d차 트렌드를 제거할 수 있다.)
   d : 누적차수

 - ARIMA 모델 : d번의 차분을 적용해 시계열을 정상 상태로 변환한 후 일반적인 ARMA 모델 적용.
 - --> 예측을 수행할 때 ARMA 모델을 사용한 다음 차분으로 뺐던 값을 다시 더함.

SARIMA 모델 (Seasonal ARIMA) : ARIMA + 계절 항 추가.
 - 총 하이퍼파라미터 : p,d,q(for ARIMA), P,D,Q(for 계절성 패턴.), s(for 계절성 패턴의 간격) 총 7개.


### 15.4.2 단기기억 문제 해결하기  
LSTM(Long Short Term Memory) 셀 (c가 장기 상태, h가 단기 상태)  
![image](https://github.com/user-attachments/assets/6c7bf4d2-8746-46a1-a925-b238bc96947c)  
: 핵심은 네트워크가 장기 상태에 저장할 것, 버릴 것, 읽어들일 것을 학습하는 것.  
 - 과거 장기 상태는 삭제 게이트에서 일부 상태를 삭제하고, 덧셈 연산으로 새로운 상태를 기억함. 이것이 최종적인 장기 상태.  
 - 또한 덧셈 연산 후 복사되어 tanh함수를 거쳐 단기 상태가 됨. 이 time step에서의 출력 y(t)와 동일.
 - main 층은 g이다. 이 층은 현재 입력 x(t)와 단기 상태 h(t-1)을 분석함.
 - 이후 이 층에서의 중요한 부분이 장기 기억 상태에 저장됨.
 - 나머지 FC층은 전부 게이트 제어기이다. 활성함수가 로지스틱이라서 0을 출력하면 닫고, 1을 출력하면 게이트를 연다.
![image](https://github.com/user-attachments/assets/0c8ea374-ca4b-485e-ae73-c38bf40cb083)
![image](https://github.com/user-attachments/assets/829b53c6-86f6-415d-a78a-88d27b7dbb98)

