### AutoEncoder   
    : 단순히 입력을 출력으로 복사하는 방법을 배운다. 그러나 잠재 표현의 크기를 제한하거나, 잡음을 추가하는 등 이에 제약을 가한다.   
    autoencoder는 이런 제약들 덕분에 단순히 입력을 출력으로 복사하는 것이 아니라, 입력을 효율적으로 표현할 수 있는 방법을 학습한다.  

### GAN  
    : 생성자와, 판별자가 적대적 훈련을 통해 새로운 가짜 데이터를 생성할 수 있도록 학습한다.  

### Diffusion Model  

***

## 17.1 효율적인 데이터 표현  
 - 오토인코더는 입력을 받아 효율적인 내부 표현으로 바꾸고 입력과 가장 가까운 어떤 것을 출력한다.  
   이 과정에서 인코더(인지 네트워크), 디코더(생성 네트워크)가 필요하다.  
 - 재구성 손실 : 오토인코더가 입력을 재구성하는 과정에서 재구성이 입력과 다를 때 모델에 부과하는 벌점.  
 - 과소완전 : 내부의 표현이 입력 데이터보다 저차원인 오토인코더.  

 - 과소완전 선형 오토인코더는 사실 PCA와 같다.  
![image](https://github.com/user-attachments/assets/23bb5ffc-a539-4020-be09-4248a90acd76)  

## 17.3 적층 오토인코더  
 : 은닉 층을 여러 개 가진 오토인코더.  
 - 그러나 오토인코더가 너무 강력해지면 안된다. 각 입력데이터를 한 숫자로 매핑하는 등의 과대적합될 수 있기 때문.  
![image](https://github.com/user-attachments/assets/f55e2fd4-9873-446d-945b-269ba285d463)

적층 오토인코더로 비지도 학습도 가능하다.  
![image](https://github.com/user-attachments/assets/3e920b84-0f6f-44c9-8e23-49b2dd5e5f7c)  

### 17.3.5 가중치 묶기  
 : 오토인코더가 완벽히 대칭일 땐 디코더의 가중치와 인코더의 가중치를 묶는 것도 일반적인 방법이다.  
 모델 전체의 가중치가 절반으로 줄어들어 훈련 속도가 증가하고 과대적합의 위험이 줄어든다.  

### 17.3.6 오코인코더 한 개씩 훈련하기  
 : 한 번에 오토인코더 전체를 훈련하는 것이 아니라 오토인코더 하나를 훈련하고 이를 쌓아올려서 하나의 적층 오토인코더를 만드는 것.  
 ![image](https://github.com/user-attachments/assets/177652e3-e76d-4840-9a31-d78d032031fd)  

## 17.4 합성곱 오토인코더  
인코더 : convolution 층과 pooling층으로 이루어진 전형적인 CNN이다.  
디코더 : 거꾸로 작동해햐 한다. 이미지의 스케일을 늘리고 깊이를 원본 차원으로 되돌려야 한다.  

## 17.5 잡음 제거 오토인코더  
 : 맨 위에 있는 오토인코더의 설명처럼 잡음을 제거하며 원본 입력을 복원하도록 훈련하는 오토인코더.  
 잡음은 입력에 순수한 가우스 잡음이나 드롭아웃처럼 랜덤으로 잡음을 껴서 발생시킬 수 있다.  
 ![image](https://github.com/user-attachments/assets/8ab51a7d-c05b-413c-8c1a-67ff3baf2a72)   
 ![image](https://github.com/user-attachments/assets/24c1bbb8-aa35-49df-bd3e-ba344381aaf7)  

 ## 17.6 희소 오토인코더  
  : 좋은 특성을 추출하도록 만드는 또 다른 제약의 방식은 희소(sparsity)이다.  
  cost function에 적절한 항을 추가하여 코딩층에서 활성화되는 뉴런을 n%로 강제할 수 있다.  
  --> 철저한 분업보단, 모두가 중요한 특성을 어느정도 추출할 수 있을 때 더 성능이 좋아진다(?)  


## 17.7 변이형 오토인코더  


## 17.8 GAN  
생성자 : 랜덤한 분포를 입력으로 받고 이미지와 합쳐진, 그럴듯한 가상의 비슷한 이미지를 생성함.  
판별자 : 생성자의 가짜 이미지 or training set의 진짜 이미지를 입력으로 받아 진위여부를 결정함.  
![image](https://github.com/user-attachments/assets/b133c29f-1ef2-49dc-8e39-aef258654635)  
과정)  
1. 판별자를 훈련시킴 - 가짜 이미지는 0으로, 진짜 이미지는 1로 레이블링해서 학습.  
2. 생성자를 훈련시킴  
3. 생성자가 생성한 이미지의 레이블을 1로 설정한 후에 판별자에 넣음.(여기선 판별자가 학습하지 않는다)  

 - 생성자는 판별자의 loss function의 그래디언트를 입력으로 받음.  
 - 생성자가 직접 진짜 데이터를 보지 않고, 판별자가 전달해주는 그래디언트를 통해 간접적으로 진짜 데이터의 정보를 학습한다.  
 - 그래서 판별자의 성능이 좋아질수록 생성자의 성능도 좋아진다.  

 - 생성자는 오토인코더의 디코더와 비슷하고, 판별자는 일반적인 이진 분류기이다.  

### 17.8.1 GAN 훈련의 어려움   
내시 균형(게임 이론에서 나온 단어) : 다른 플레이어가 전략을 수정하지 않을 것이므로 어떤 플레이어도 자신의 전략을 수정하지 않으려는 상태.  
 - 가장 Optimal한 상태이다.
 - 생성자는 판별자를 속일 수 있는 완벽한 가짜 데이터를 생성하고, 판별자는 가짜 데이터를 완벽히 구별 못하는 상태.
 - GAN이 수렴한 상태이다. 그러나 실질적으론 불가능하다.

 - 생성자는 판별자를 속이기 쉬운 것만 생성하려고 한다.
 - 그래서 정확도가 낮은 LABEL ex) 고양이 만 생성하다보면 다른 패턴에 대한 생성은 잊어버린다.
 - GAN은 실제 데이터 분포를 완벽하게 모델링하지 못하고, 일부 특정한 특징만 학습하게 된다.


### 17.8.2 심층 합성곱 GAN (DCGAN)  
 : 완전연결 NN을 쓰던 기존의 생성자와 판별자에 CNN을 사용한 것.  
![image](https://github.com/user-attachments/assets/2bf3df57-9a22-40e8-8048-f2b0aa6ff3c5)  
![image](https://github.com/user-attachments/assets/33e34dde-5e7d-4859-ad85-8559493e1403)  

### 17.8.3 ProGAN  
 - 기존 GAN은 한 번에 전체 해상도를 학습하려하기 때문에 초반에 네트워크가 잘 수렴하지 않았다.
 - 기존 GAN은 해상도가 높아질수록 매개변수의 개수가 많아지면서 학습이 어려워지는 문제(그래디언트 소실/폭발)가 있었다.

   -> 그래서 ProGAN은 처음엔 저해상도로부터 시작하여 점진적으로 해상도를 높여가며 학습.

### 17.8.4 StyleGAN  
기존 GAN과 달리, 스타일을 조정할 수 있다.  
기존 : 랜덤 노이즈 -> CNN -> 이미지 생성   
StyleGAN : 랜덤 노이즈 -> 스타일 변환 네트워크 -> 스타일 벡터 생성.  
이 스타일 변화 네트워크로 인해 특정 스타일을 조정할 수 있다.  


## 17.9 확산 모델  



  

 



