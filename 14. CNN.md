# 14. CNN  
![image](https://github.com/user-attachments/assets/781b8370-5c12-44b1-86c7-68fb10b0ca8d)
 - 첫 번째 층에선 작은 저수준 특성에 집중하고, 그다음 은닉 층에선 더 큰 고수준 특성을 분석한다.
 - 패딩 : 컨볼루션 연산에서 출력 크기를 조정하고, 가장자리 픽셀들도 연산에 잘 반영되도록 하는 기법.  
![image](https://github.com/user-attachments/assets/b0595c93-af55-40a3-a7e0-2d4da776ab0b)  

## 14.2.1 필터  
필터의 역할 : ![image](https://github.com/user-attachments/assets/7f640855-68b8-4844-bffa-6e94c8224302)  
수직 필터 : 가운데 수직으로 1이 있고 나머지는 0. 수평 필터 : 가운데 수평으로 1이 있고 나머지는 0.  
 - 필터는 수동으로 만드는 게 아니라, 훈련하는 동안 합성곱 층이 자동으로 최적의 필터를 찾음.

![image](https://github.com/user-attachments/assets/8cc83a13-8031-435a-8e69-b92867807974)  
1 convolutional layer가 input에 여러 필터를 동시에 적용하여 input에 있는 여러 특성을 감지할 수도 있다.  
Feature Map : 1개의 filter가 생성하는 출력.  
![image](https://github.com/user-attachments/assets/12515a78-a2ba-44b2-8a78-361d528ce2ba)  

## 14.3 Pooling layer  
풀링 층의 목적 : 계산량과 메모리, (오버피팅을 방지하는) 파라미터 수를 줄이기 위해 입력 이미지의 축소판을 만드는 것.  
플링은 가중치가 없고, 기존 값들 중에서 최대 or 평균 값등을 대표로 사용함.  
![image](https://github.com/user-attachments/assets/2e33c534-70cf-4705-ac38-c76947b3a66d)  
 - 또한 회전과 확대, 축소와 같은 작은 변화에 대한 약간의 불변성도 제공한다.
![image](https://github.com/user-attachments/assets/d3d5dacb-3956-4e25-a307-b5912db5b79e)  
 - 그러나 입력값의 다수를 잃게 될 뿐만 아니라 불변성이 크게 필요하지 않는 분야에선 좋지 않다.

## 14.5 CNN  
![image](https://github.com/user-attachments/assets/d272b994-9652-44c6-a95c-bba73176c75c)  
네트워크를 통과할수록 이미지는 점점 작아지지만 합성곱 층 때문에 더 깊어짐. 더 많은 특성 맵.  

### 14.5.1 LeNet  
![image](https://github.com/user-attachments/assets/7f518691-373b-4a12-b77b-605cc73fd9ac)  
### 14.5.2 AlexNet  
![image](https://github.com/user-attachments/assets/e72a5cdd-30af-48db-9677-317b0dccf87d)  
### 14.5.3 GoogLeNet  
 - 인셉션 모듈
![image](https://github.com/user-attachments/assets/bb4e2c5e-c0f7-46c8-8b24-a3025583375b)  
 - 1 x 1 커널의 합성곱 층의 이유 : 공간상의 패턴을 잡을 수는 없지만 깊이 차원(채널)을 따라 놓인 패턴을 잡을 수 있다.
 - 입력보다 더 작은 특성 맵을 활용하므로 차원을 줄인다는 의미의 병목 층의 역할을 한다.
![image](https://github.com/user-attachments/assets/6c599aae-658f-47e2-9435-3ab9ef95aa63)
### 14.5.5 ResNet  







